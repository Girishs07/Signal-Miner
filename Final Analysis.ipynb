{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d96c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data with standardized company locations. 8 companies mapped.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv('linkedin_job_listings_enhanced.csv')\n",
    "\n",
    "\n",
    "company_headquarters = {\n",
    "    'Chargebee': 'Chennai, India',\n",
    "    'Plum Insurance': 'Bangalore, India',\n",
    "    'Yellow.ai': 'San Mateo, USA',\n",
    "    'Graphy': 'Bangalore, India',\n",
    "    'Kala.ai': 'Nicosia, Cyprus',\n",
    "    'Razorpay': 'Bangalore, India',\n",
    "    'BrowserStack': 'Mumbai, India',\n",
    "    'Meesho': 'Bangalore, India'\n",
    "}\n",
    "\n",
    "\n",
    "def clean_company_name(name):\n",
    "    return re.sub(r'\\s*hiring.*', '', name).strip()\n",
    "\n",
    "def get_headquarters(company_name):\n",
    "    clean_name = clean_company_name(company_name)\n",
    "    return company_headquarters.get(clean_name, 'Unknown')\n",
    "\n",
    "\n",
    "df['company_name'] = df['company_name'].apply(clean_company_name)\n",
    "df['location'] = df['company_name'].apply(get_headquarters)\n",
    "\n",
    "\n",
    "df.to_csv('location changed datas.csv', index=False)\n",
    "\n",
    "print(f\"Saved data with standardized company locations. {len(company_headquarters)} companies mapped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c45c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate job URLs in merged data: 0\n",
      "Merging completed successfully!\n",
      "Final dataset shape: (320, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('linkedin_job_listings_cleaned.csv')  \n",
    "df2 = pd.read_csv('location changed datas.csv')  \n",
    "\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    df1[['company_name', 'department', 'seniority', 'job_url', \n",
    "         'growth_signal_tag', 'processed_timestamp',\n",
    "         'growth_tag_remote_hiring_focus', 'growth_tag_product_team_buildout',\n",
    "         'job_title_clean']],\n",
    "    df2[['job_url', 'location']], \n",
    "    on='job_url',\n",
    "    how='inner'  \n",
    ")\n",
    "\n",
    "print(f\"Duplicate job URLs in merged data: {merged_df['job_url'].duplicated().sum()}\")\n",
    "\n",
    "final_columns = [\n",
    "    'company_name', 'department', 'seniority', 'job_url', \n",
    "    'growth_signal_tag', 'processed_timestamp',\n",
    "    'growth_tag_remote_hiring_focus', 'growth_tag_product_team_buildout',\n",
    "    'job_title_clean', 'location'\n",
    "]\n",
    "merged_df = merged_df[final_columns]\n",
    "\n",
    "merged_df.to_csv('final_merged_dataset.csv', index=False)\n",
    "\n",
    "print(\"Merging completed successfully!\")\n",
    "print(f\"Final dataset shape: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9defbbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning vs After cleaning:\n",
      "Original: Product Marketing Manager In Salt Lake ...\n",
      "Cleaned: Product Marketing Manager\n",
      "\n",
      "Original: Staff Product Manager In Chennai, Tamil ...\n",
      "Cleaned: Staff Product Manager\n",
      "\n",
      "Original: Large Enterprise Program Manager\n",
      "Cleaned: Large Enterprise Program Manager\n",
      "\n",
      "Original: Product Marketing Manager -Saas\n",
      "Cleaned: Product Marketing Manager -Saas\n",
      "\n",
      "Original: Product Marketing Manager\n",
      "Cleaned: Product Marketing Manager\n",
      "\n",
      "Original: Business Development Representative\n",
      "Cleaned: Business Development Representative\n",
      "\n",
      "Original: Business Development Representative\n",
      "Cleaned: Business Development Representative\n",
      "\n",
      "Original: Business Development Representative Emea\n",
      "Cleaned: Business Development Representative Emea\n",
      "\n",
      "Original: Enterprise Business Development Representative\n",
      "Cleaned: Enterprise Business Development Representative\n",
      "\n",
      "Original: Enterprise Account Executive In San Francisco ...\n",
      "Cleaned: Enterprise Account Executive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "merged_df = merged_df[final_columns]\n",
    "\n",
    "\n",
    "def clean_job_title(title):\n",
    "    \"\"\"\n",
    "    Clean job titles by removing:\n",
    "    - Locations (in ...)\n",
    "    - Special characters and parenthetical text\n",
    "    - Company names\n",
    "    - Unwanted prefixes/suffixes\n",
    "    \"\"\"\n",
    "    if pd.isna(title):\n",
    "        return title\n",
    "    \n",
    "  \n",
    "    title = re.sub(r'\\s*(?:in|at|for|on|from|by|near)\\s+.*?(?:\\s*\\.{3})?$', '', title, flags=re.IGNORECASE)\n",
    "    \n",
    "\n",
    "    title = re.sub(r'\\(.*?\\)', '', title)\n",
    "    title = re.sub(r'[^\\w\\s-]', ' ', title)\n",
    "    \n",
    "    \n",
    "    title = re.sub(r'^\\s*(?:hiring|looking for|seeking|wanted)\\s+', '', title, flags=re.IGNORECASE)\n",
    "    title = re.sub(r'\\s*(?:job|position|role|opening)\\s*$', '', title, flags=re.IGNORECASE)\n",
    "    \n",
    "  \n",
    "    title = re.sub(r'\\s*(?:at|from|for)\\s+[\\w\\s]+$', '', title, flags=re.IGNORECASE)\n",
    "    \n",
    "  \n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    title = title.title()  \n",
    "    \n",
    "    return title\n",
    "\n",
    "\n",
    "df = pd.read_csv('final_merged_dataset.csv')\n",
    "\n",
    "\n",
    "df['clean_title'] = df['job_title_clean'].apply(clean_job_title)\n",
    "\n",
    "\n",
    "print(\"Before cleaning vs After cleaning:\")\n",
    "for orig, clean in zip(df['job_title_clean'].head(10), df['clean_title'].head(10)):\n",
    "    print(f\"Original: {orig}\\nCleaned: {clean}\\n\")\n",
    "\n",
    "df.to_csv('final merged and clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47d4f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final merged and clean.csv')\n",
    "\n",
    "df = df.drop('job_title_clean', axis=1)\n",
    "\n",
    "\n",
    "df = df.rename(columns={'clean_title': 'Job_Title'})\n",
    "\n",
    "\n",
    "desired_order = [\n",
    "    'company_name',\n",
    "    'Job_Title',\n",
    "    'department',\n",
    "    'location',\n",
    "    'seniority',\n",
    "    'job_url',\n",
    "    'growth_signal_tag',\n",
    "    'processed_timestamp',\n",
    "    'growth_tag_remote_hiring_focus',\n",
    "    'growth_tag_product_team_buildout'\n",
    "]\n",
    "\n",
    "df = df[desired_order]\n",
    "\n",
    "df.to_csv('cleaned datas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44768ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed successfully!\n",
      "Added columns: ['New Product Initiative', 'Engineering Buildout', 'Design Overhaul', 'Go-To-Market Expansion', 'General Hiring']\n",
      "New dataset shape: (320, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('cleaned datas.csv')\n",
    "df2 = pd.read_csv('extra cleaned columns.csv')\n",
    "\n",
    "growth_tags = [\n",
    "    'New Product Initiative',\n",
    "    'Engineering Buildout', \n",
    "    'Design Overhaul',\n",
    "    'Go-To-Market Expansion',\n",
    "    'General Hiring'\n",
    "]\n",
    "\n",
    "\n",
    "missing_tags = [tag for tag in growth_tags if tag not in df2.columns]\n",
    "if missing_tags:\n",
    "    print(f\"Warning: These growth tags not found in second dataset: {missing_tags}\")\n",
    "    growth_tags = [tag for tag in growth_tags if tag in df2.columns]\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    df1,\n",
    "    df2[['job_url'] + growth_tags],  \n",
    "    on='job_url',\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "if merged_df['job_url'].duplicated().any():\n",
    "    print(\"Warning: Duplicate job_url values detected after merge\")\n",
    "    merged_df = merged_df.drop_duplicates(subset=['job_url'])\n",
    "\n",
    "\n",
    "merged_df.to_csv('Final_Cleaned_Datasets.csv', index=False)\n",
    "\n",
    "print(\"Merge completed successfully!\")\n",
    "print(f\"Added columns: {growth_tags}\")\n",
    "print(f\"New dataset shape: {merged_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
